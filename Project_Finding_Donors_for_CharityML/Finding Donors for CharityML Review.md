# Finding Donors for CharityML Review

![Project_Finding_Donors_for_CharityML](../img/Project_Finding_Donors_for_CharityML.png)

### Meets Specifications 

Hi!!

I'm by chance the first reviewer ![:sunglasses:](https://review.udacity.com/assets/images/emojis/sunglasses.png)

I'm glad to see how you've progressed, the project looks fantastic!

Hope to have helped you and enjoy the rest of the course! ![:tada:](https://review.udacity.com/assets/images/emojis/tada.png)



### Exploring the Data 

Student's implementation correctly calculates the following:

- Number of records
- Number of individuals with income >$50,000
- Number of individuals with income <=$50,000
- Percentage of individuals with income > $50,000

This part was already fine!



### Preparing the Data 

Student correctly implements one-hot encoding for the feature and income data.

This part was already fine!



### Evaluating Model Performance 

Student correctly calculates the benchmark score of the naive predictor for both accuracy and F1 scores.

Already fine!

The pros and cons or application for each model is provided with reasonable justification why each model was chosen to be explored.

Please list all the references you use while listing out your pros and cons.

Great, now you give links to the resources used. However, in the future you should try to be more precise and avoid giving links to general webpages like the scikit-learn front page https://scikit-learn.org/stable/,

Student successfully implements a pipeline in code that will train and predict on the supervised learning algorithm given.

![:+1:](https://review.udacity.com/assets/images/emojis/%2B1.png)



Student correctly implements three supervised learning models and produces a performance visualization.

Now the cell has run and the results are visible! ![:+1:](https://review.udacity.com/assets/images/emojis/%2B1.png)



### Improving Results 

Justification is provided for which model appears to be the best to use given computational cost, model performance, and the characteristics of the data.

Already correct!

Student is able to clearly and concisely describe how the optimal model works in layman's terms to someone who is not familiar with machine learning nor has a technical background.

A really good example for the Layman's terms description. Well done! ![:clap:](https://review.udacity.com/assets/images/emojis/clap.png)



The final model chosen is correctly tuned using grid search with at least one parameter using at least three settings. If the model does not need any parameter tuning it is explicitly stated with reasonable justification.

Well done, now at least one of the parameters has 3 values.

Student reports the accuracy and F1 score of the optimized, unoptimized, models correctly in the table provided. Student compares the final model results to previous results obtained.

Well done reporting all results and comparing them to the Naïve Bayes results.



### Feature Importance 

Student ranks five features which they believe to be the most relevant for predicting an individual's’ income. Discussion is provided for why these features were chosen.

Student correctly implements a supervised learning model that makes use of the `feature_importances_` attribute. Additionally, student discusses the differences or similarities between the features they considered relevant and the reported relevant features.

Now results are reproducible!

Student analyzes the final model's performance when only the top 5 features are used and compares this performance to the optimized model from **Question 5**.

Great!!

You compare the performance of the model with the optimized model and give thoughts about when you would choose to reduce the set of features. 

As you say, had you aimed at reducing the training time, that'd had been a good option. Sometimes the change in performance is not significant and it is well worth to take less time in fitting the model.

---

